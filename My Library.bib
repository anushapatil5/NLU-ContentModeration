
@inproceedings{pavlopoulos_deeper_2017,
	address = {Copenhagen, Denmark},
	title = {Deeper {Attention} to {Abusive} {User} {Content} {Moderation}},
	url = {https://www.aclweb.org/anthology/D17-1117},
	doi = {10.18653/v1/D17-1117},
	abstract = {Experimenting with a new dataset of 1.6M user comments from a news portal and an existing dataset of 115K Wikipedia talk page comments, we show that an RNN operating on word embeddings outpeforms the previous state of the art in moderation, which used logistic regression or an MLP classifier with character or word n-grams. We also compare against a CNN operating on word embeddings, and a word-list baseline. A novel, deep, classificationspecific attention mechanism improves the performance of the RNN further, and can also highlight suspicious words for free, without including highlighted words in the training data. We consider both fully automatic and semi-automatic moderation.},
	urldate = {2020-04-15},
	booktitle = {Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Pavlopoulos, John and Malakasiotis, Prodromos and Androutsopoulos, Ion},
	month = sep,
	year = {2017},
	pages = {1125--1135},
	file = {Full Text PDF:C\:\\Users\\Optimus\\Zotero\\storage\\2SUPR498\\Pavlopoulos et al. - 2017 - Deeper Attention to Abusive User Content Moderatio.pdf:application/pdf}
}

@inproceedings{dadvar_improving_2013,
	address = {Berlin, Heidelberg},
	title = {Improving {Cyberbullying} {Detection} with {User} {Context}},
	isbn = {978-3-642-36973-5},
	abstract = {The negative consequences of cyberbullying are becoming more alarming every day and technical solutions that allow for taking appropriate action by means of automated detection are still very limited. Up until now, studies on cyberbullying detection have focused on individual comments only, disregarding context such as users' characteristics and profile information. In this paper we show that taking user context into account improves the detection of cyberbullying.},
	booktitle = {Advances in {Information} {Retrieval}},
	publisher = {Springer Berlin Heidelberg},
	author = {Dadvar, Maral and Trieschnigg, Dolf and Ordelman, Roeland and de Jong, Franciska},
	editor = {Serdyukov, Pavel and Braslavski, Pavel and Kuznetsov, Sergei O. and Kamps, Jaap and Rüger, Stefan and Agichtein, Eugene and Segalovich, Ilya and Yilmaz, Emine},
	year = {2013},
	pages = {693--696},
	file = {(PDF) Improving Cyberbullying Detection with User .pdf:C\:\\Users\\Optimus\\Zotero\\storage\\9PMT5NI3\\(PDF) Improving Cyberbullying Detection with User .pdf:application/pdf}
}

@misc{jhaver_human-machine_2019,
	title = {Human-{Machine} {Collaboration} for {Content} {Regulation}: {The} {Case} of {Reddit} {Automoderator}},
	shorttitle = {Human-{Machine} {Collaboration} for {Content} {Regulation}},
	url = {https://doi.org/10.1145/3338243},
	abstract = {What one may say on the internet is increasingly controlled by a mix of automated programs, and decisions made by paid and volunteer human moderators. On the popular social media site Reddit, moderators heavily rely on a configurable, automated program called “Automoderator” (or “Automod”). How do moderators use Automod? What advantages and challenges does the use of Automod present? We participated as Reddit moderators for over a year, and conducted interviews with 16 moderators to understand the use of Automod in the context of the sociotechnical system of Reddit. Our findings suggest a need for audit tools to help tune the performance of automated mechanisms, a repository for sharing tools, and improving the division of labor between human and machine decision making. We offer insights that are relevant to multiple stakeholders—creators of platforms, designers of automated regulation systems, scholars of platform governance, and content moderators.},
	urldate = {2020-04-15},
	publisher = {Association for Computing Machinery},
	author = {Jhaver, Shagun and Birman, Iris and Gilbert, Eric and Bruckman, Amy},
	month = jul,
	year = {2019},
	keywords = {automated moderation, Automod, Content moderation, future of work, mixed initiative, platform governance},
	file = {Full Text PDF:C\:\\Users\\Optimus\\Zotero\\storage\\DURCT62W\\Jhaver et al. - 2019 - Human-Machine Collaboration for Content Regulation.pdf:application/pdf}
}

@article{zhang_sensitivity_2016,
	title = {A {Sensitivity} {Analysis} of (and {Practitioners}' {Guide} to) {Convolutional} {Neural} {Networks} for {Sentence} {Classification}},
	url = {http://arxiv.org/abs/1510.03820},
	abstract = {Convolutional Neural Networks (CNNs) have recently achieved remarkably strong performance on the practically important task of sentence classification (kim 2014, kalchbrenner 2014, johnson 2014). However, these models require practitioners to specify an exact model architecture and set accompanying hyperparameters, including the filter region size, regularization parameters, and so on. It is currently unknown how sensitive model performance is to changes in these configurations for the task of sentence classification. We thus conduct a sensitivity analysis of one-layer CNNs to explore the effect of architecture components on model performance; our aim is to distinguish between important and comparatively inconsequential design decisions for sentence classification. We focus on one-layer CNNs (to the exclusion of more complex models) due to their comparative simplicity and strong empirical performance, which makes it a modern standard baseline method akin to Support Vector Machine (SVMs) and logistic regression. We derive practical advice from our extensive empirical results for those interested in getting the most out of CNNs for sentence classification in real world settings.},
	urldate = {2020-04-18},
	journal = {arXiv:1510.03820 [cs]},
	author = {Zhang, Ye and Wallace, Byron},
	month = apr,
	year = {2016},
	note = {arXiv: 1510.03820},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:C\:\\Users\\Optimus\\Zotero\\storage\\UTMQ6KVP\\Zhang and Wallace - 2016 - A Sensitivity Analysis of (and Practitioners' Guid.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Optimus\\Zotero\\storage\\JX9JCQLJ\\1510.html:text/html}
}

@article{davidson_automated_2017,
	title = {Automated {Hate} {Speech} {Detection} and the {Problem} of {Offensive} {Language}},
	url = {http://arxiv.org/abs/1703.04009},
	abstract = {A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language. Lexical detection methods tend to have low precision because they classify all messages containing particular terms as hate speech and previous work using supervised learning has failed to distinguish between the two categories. We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords. We use crowd-sourcing to label a sample of these tweets into three categories: those containing hate speech, only offensive language, and those with neither. We train a multi-class classifier to distinguish between these different categories. Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difficult. We find that racist and homophobic tweets are more likely to be classified as hate speech but that sexist tweets are generally classified as offensive. Tweets without explicit hate keywords are also more difficult to classify.},
	urldate = {2020-04-18},
	journal = {arXiv:1703.04009 [cs]},
	author = {Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.04009},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: To appear in the Proceedings of ICWSM 2017. Please cite that version},
	file = {arXiv Fulltext PDF:C\:\\Users\\Optimus\\Zotero\\storage\\XE45UMA5\\Davidson et al. - 2017 - Automated Hate Speech Detection and the Problem of.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Optimus\\Zotero\\storage\\T7EWZRNP\\1703.html:text/html}
}

@article{xu_sentiment_2019,
	title = {Sentiment {Analysis} of {Comment} {Texts} {Based} on {BiLSTM}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2909919},
	abstract = {With the rapid development of Internet technology and social networks, a large number of comment texts are generated on the Web. In the era of big data, mining the emotional tendency of comments through artificial intelligence technology is helpful for the timely understanding of network public opinion. The technology of sentiment analysis is a part of artificial intelligence, and its research is very meaningful for obtaining the sentiment trend of the comments. The essence of sentiment analysis is the text classification task, and different words have different contributions to classification. In the current sentiment analysis studies, distributed word representation is mostly used. However, distributed word representation only considers the semantic information of word, but ignore the sentiment information of the word. In this paper, an improved word representation method is proposed, which integrates the contribution of sentiment information into the traditional TF-IDF algorithm and generates weighted word vectors. The weighted word vectors are input into bidirectional long short term memory (BiLSTM) to capture the context information effectively, and the comment vectors are better represented. The sentiment tendency of the comment is obtained by feedforward neural network classifier. Under the same conditions, the proposed sentiment analysis method is compared with the sentiment analysis methods of RNN, CNN, LSTM, and NB. The experimental results show that the proposed sentiment analysis method has higher precision, recall, and F1 score. The method is proved to be effective with high accuracy on comments.},
	journal = {IEEE Access},
	author = {Xu, Guixian and Meng, Yueting and Qiu, Xiaoyu and Yu, Ziheng and Wu, Xu},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {artificial intelligence, artificial intelligence technology, BiLSTM, comment texts, comment vectors, data mining, Data mining, Dictionaries, distributed word representation, improved word representation method, Internet, Internet technology, network public opinion, neural nets, Neural networks, pattern classification, Semantics, sentiment analysis, Sentiment analysis, sentiment analysis method, sentiment information, sentiment tendency, sentiment trend, social network, social networking (online), social networks, Task analysis, text classification task, weighted word vectors},
	pages = {51522--51532},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Optimus\\Zotero\\storage\\MFCUTKZV\\Xu et al. - 2019 - Sentiment Analysis of Comment Texts Based on BiLST.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Optimus\\Zotero\\storage\\G65KHXU4\\8684825.html:text/html}
}

@techreport{mahajan_explainable_2020,
	title = {Explainable {AI} approach towards {Toxic} {Comment} {Classification}},
	institution = {EasyChair},
	author = {Mahajan, Aditya and Shah, Divyank and Jafar, Gibraan},
	year = {2020},
	file = {EasyChair-Preprint-2773.pdf:D\:\\Downloads\\EasyChair-Preprint-2773.pdf:application/pdf}
}

@article{wolf_huggingfaces_2020,
	title = {{HuggingFace}'s {Transformers}: {State}-of-the-art {Natural} {Language} {Processing}},
	shorttitle = {{HuggingFace}'s {Transformers}},
	url = {http://arxiv.org/abs/1910.03771},
	abstract = {Recent advances in modern Natural Language Processing (NLP) research have been dominated by the combination of Transfer Learning methods with large-scale language models, in particular based on the Transformer architecture. With them came a paradigm shift in NLP with the starting point for training a model on a downstream task moving from a blank specific model to a general-purpose pretrained architecture. Still, creating these general-purpose models remains an expensive and time-consuming process restricting the use of these methods to a small sub-set of the wider NLP community. In this paper, we present HuggingFace's Transformers library, a library for state-of-the-art NLP, making these developments available to the community by gathering state-of-the-art general-purpose pretrained models under a unified API together with an ecosystem of libraries, examples, tutorials and scripts targeting many downstream NLP tasks. HuggingFace's Transformers library features carefully crafted model implementations and high-performance pretrained weights for two main deep learning frameworks, PyTorch and TensorFlow, while supporting all the necessary tools to analyze, evaluate and use these models in downstream tasks such as text/token classification, questions answering and language generation among others. The library has gained significant organic traction and adoption among both the researcher and practitioner communities. We are committed at HuggingFace to pursue the efforts to develop this toolkit with the ambition of creating the standard library for building NLP systems. HuggingFace's Transformers library is available at {\textbackslash}url\{https://github.com/huggingface/transformers\}.},
	urldate = {2020-04-20},
	journal = {arXiv:1910.03771 [cs]},
	author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Rémi and Funtowicz, Morgan and Brew, Jamie},
	month = feb,
	year = {2020},
	note = {arXiv: 1910.03771},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 11 pages, 1 figure, more details at https://github.com/huggingface/transformers},
	file = {arXiv Fulltext PDF:C\:\\Users\\Optimus\\Zotero\\storage\\Y4MNSF33\\Wolf et al. - 2020 - HuggingFace's Transformers State-of-the-art Natur.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Optimus\\Zotero\\storage\\ELL8S9ZC\\1910.html:text/html}
}

@article{beltagy_scibert_2019,
	title = {{SciBERT}: {A} {Pretrained} {Language} {Model} for {Scientific} {Text}},
	shorttitle = {{SciBERT}},
	url = {http://arxiv.org/abs/1903.10676},
	abstract = {Obtaining large-scale annotated data for NLP tasks in the scientific domain is challenging and expensive. We release SciBERT, a pretrained language model based on BERT (Devlin et al., 2018) to address the lack of high-quality, large-scale labeled scientific data. SciBERT leverages unsupervised pretraining on a large multi-domain corpus of scientific publications to improve performance on downstream scientific NLP tasks. We evaluate on a suite of tasks including sequence tagging, sentence classification and dependency parsing, with datasets from a variety of scientific domains. We demonstrate statistically significant improvements over BERT and achieve new state-of-the-art results on several of these tasks. The code and pretrained models are available at https://github.com/allenai/scibert/.},
	urldate = {2020-04-21},
	journal = {arXiv:1903.10676 [cs]},
	author = {Beltagy, Iz and Lo, Kyle and Cohan, Arman},
	month = sep,
	year = {2019},
	note = {arXiv: 1903.10676},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: https://github.com/allenai/scibert},
	file = {arXiv Fulltext PDF:C\:\\Users\\Optimus\\Zotero\\storage\\9Z94XBXD\\Beltagy et al. - 2019 - SciBERT A Pretrained Language Model for Scientifi.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Optimus\\Zotero\\storage\\QFTAP6FR\\1903.html:text/html}
}

@article{liu_roberta_2019,
	title = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
	shorttitle = {{RoBERTa}},
	url = {http://arxiv.org/abs/1907.11692},
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	urldate = {2020-04-21},
	journal = {arXiv:1907.11692 [cs]},
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.11692},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\Optimus\\Zotero\\storage\\9FPCG69M\\Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining App.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Optimus\\Zotero\\storage\\A2GR4XIF\\1907.html:text/html}
}